{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Mbi7rZjDMOm",
        "outputId": "7b97095f-d788-4353-ba61-ad373469b901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark==3.4.1 in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark==3.4.1) (0.10.9.7)\n",
            "Requirement already satisfied: spark-nlp==5.2.3 in /usr/local/lib/python3.11/dist-packages (5.2.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.4.1\n",
        "!pip install spark-nlp==5.2.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sentiment_llm_pyspark.py\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import warnings\n",
        "\n",
        "# Ignore warnings from Hugging Face\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# 1. Create sample data\n",
        "data = {\n",
        "    \"sentence\": [\n",
        "        \"I love this product!\", \"This is the worst service ever.\", \"Absolutely fantastic experience.\",\n",
        "        \"I'm not happy with the results.\", \"The movie was okay, not great.\", \"What a wonderful surprise!\",\n",
        "        \"I would not recommend this.\", \"Such a delightful day.\", \"Terrible customer support.\",\n",
        "        \"This phone is amazing!\", \"Very disappointing performance.\", \"I'm so excited about this!\",\n",
        "        \"Could be better.\", \"Totally satisfied with my purchase.\", \"I hate how this works.\",\n",
        "        \"It exceeded my expectations!\", \"Nothing special about it.\", \"I'm impressed by the quality.\",\n",
        "        \"Worst purchase I've made.\", \"A pretty decent option.\"\n",
        "    ],\n",
        "    \"label\": [\n",
        "        \"positive\", \"negative\", \"positive\", \"negative\", \"neutral\", \"positive\", \"negative\",\n",
        "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"neutral\", \"positive\",\n",
        "        \"negative\", \"positive\", \"neutral\", \"positive\", \"negative\", \"neutral\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 2. Start Spark session\n",
        "spark = SparkSession.builder.appName(\"LLM Sentiment Evaluation\").getOrCreate()\n",
        "\n",
        "# 3. Convert data to Spark DataFrame\n",
        "df_pd = pd.DataFrame(data)\n",
        "df_spark = spark.createDataFrame(df_pd)\n",
        "\n",
        "# 4. Convert Spark â†’ Pandas for inference\n",
        "df = df_spark.toPandas()\n",
        "\n",
        "# 5. Load Hugging Face sentiment analysis model\n",
        "classifier = pipeline(\"sentiment-analysis\")  # Defaults to distilbert-base-uncased-finetuned-sst-2-english\n",
        "\n",
        "# 6. Run predictions\n",
        "def map_prediction(pred):\n",
        "    label = pred['label'].lower()\n",
        "    if label == 'positive':\n",
        "        return 'positive'\n",
        "    elif label == 'negative':\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "df['predicted'] = df['sentence'].apply(lambda x: map_prediction(classifier(x)[0]))\n",
        "\n",
        "# 7. Evaluate results\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(df['label'], df['predicted'], digits=3))\n",
        "\n",
        "print(\"\\nAccuracy Score:\", accuracy_score(df['label'], df['predicted']))\n",
        "\n",
        "# 8. Convert back to Spark for further processing if needed\n",
        "df_result_spark = spark.createDataFrame(df)\n",
        "df_result_spark.show(truncate=False)\n",
        "\n",
        "# 9. Stop Spark\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f58mchCjDwJ7",
        "outputId": "bffc03bc-550d-47a4-bacf-914dbb32fbe2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.700     1.000     0.824         7\n",
            "     neutral      0.000     0.000     0.000         4\n",
            "    positive      0.900     1.000     0.947         9\n",
            "\n",
            "    accuracy                          0.800        20\n",
            "   macro avg      0.533     0.667     0.590        20\n",
            "weighted avg      0.650     0.800     0.715        20\n",
            "\n",
            "\n",
            "Accuracy Score: 0.8\n",
            "+-----------------------------------+--------+---------+\n",
            "|sentence                           |label   |predicted|\n",
            "+-----------------------------------+--------+---------+\n",
            "|I love this product!               |positive|positive |\n",
            "|This is the worst service ever.    |negative|negative |\n",
            "|Absolutely fantastic experience.   |positive|positive |\n",
            "|I'm not happy with the results.    |negative|negative |\n",
            "|The movie was okay, not great.     |neutral |negative |\n",
            "|What a wonderful surprise!         |positive|positive |\n",
            "|I would not recommend this.        |negative|negative |\n",
            "|Such a delightful day.             |positive|positive |\n",
            "|Terrible customer support.         |negative|negative |\n",
            "|This phone is amazing!             |positive|positive |\n",
            "|Very disappointing performance.    |negative|negative |\n",
            "|I'm so excited about this!         |positive|positive |\n",
            "|Could be better.                   |neutral |negative |\n",
            "|Totally satisfied with my purchase.|positive|positive |\n",
            "|I hate how this works.             |negative|negative |\n",
            "|It exceeded my expectations!       |positive|positive |\n",
            "|Nothing special about it.          |neutral |negative |\n",
            "|I'm impressed by the quality.      |positive|positive |\n",
            "|Worst purchase I've made.          |negative|negative |\n",
            "|A pretty decent option.            |neutral |positive |\n",
            "+-----------------------------------+--------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU-ari_8Fbyp",
        "outputId": "7a8c7135-0509-4f9e-e519-3171a030564e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Artificial intelligence is transforming\""
      ],
      "metadata": {
        "id": "2rgTqIJLFme4"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = generator(prompt, max_length=50, num_return_sequences=1)\n",
        "print(\"Step 2:Generated Text:\\n\", output[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpVGVPAjFxsA",
        "outputId": "8b0ecb93-7f4f-4183-abd5-f7ef9447aea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModel.from_pretrained(\"gpt2\")\n"
      ],
      "metadata": {
        "id": "RxI3AwguF3Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the prompt\n",
        "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
        "print(\"\\nToken IDs:\\n\", tokens['input_ids'][0].tolist())"
      ],
      "metadata": {
        "id": "DnWk0s9-GAio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02e1434e"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModel.from_pretrained(\"gpt2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ca82a88"
      },
      "source": [
        "# Tokenize the prompt\n",
        "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
        "print(\"\\nToken IDs:\\n\", tokens['input_ids'][0].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    embeddings = model(**tokens).last_hidden_state\n",
        "print(\"\\nEmbeddings Shape:\\n\", embeddings.shape)\n"
      ],
      "metadata": {
        "id": "z0kHb5lwGf6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(\"\"\"\n",
        "### ðŸ§  Discussion Points\n",
        "\n",
        "- **Tokenization**: Converts text into subword units and token IDs.\n",
        "- **Embeddings**: Token IDs are mapped to dense vectors capturing meaning.\n",
        "- **Transformer Layers**: Use attention to understand relationships between tokens.\n",
        "- **Text Generation**: Predicts next words based on context and learned patterns.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "dZifE-0dGmiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch scikit-learn\n"
      ],
      "metadata": {
        "id": "69CKHSpbGn4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "8zEoHlw5G56f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "vb4vFyVrG-Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load RoBERTa model fine-tuned for sentiment analysis\n",
        "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Create sentiment analysis pipeline\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "lJo4LD22HF7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hvVx7vlnJWKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\n",
        "    \"I absolutely love this!\",\n",
        "    \"This is so frustrating and annoying.\",\n",
        "    \"What a beautiful day!\",\n",
        "    \"I can't stand this anymore.\",\n",
        "    \"Totally worth it!\",\n",
        "    \"Worst experience ever.\",\n",
        "    \"I'm really happy with the results.\",\n",
        "    \"This is not what I expected.\",\n",
        "    \"Amazing job!\",\n",
        "    \"Terrible service.\"\n",
        "]\n",
        "\n",
        "# True labels based on manual annotation\n",
        "true_labels = [\n",
        "    \"positive\", \"negative\", \"positive\", \"negative\", \"positive\",\n",
        "    \"negative\", \"positive\", \"negative\", \"positive\", \"negative\"]\n"
      ],
      "metadata": {
        "id": "eW2qGt_8HNEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {'label_0': 'negative', 'label_1': 'neutral', 'label_2': 'positive'}\n",
        "predicted_labels = [label_mapping[sentiment_pipeline(text)[0]['label'].lower()] for text in test_sentences]\n",
        "print(predicted_labels)"
      ],
      "metadata": {
        "id": "UFj23x0yHOaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Evaluate using multiclass metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='macro')\n",
        "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(f\"Accuracy:  {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1 Score:  {f1:.2f}\")"
      ],
      "metadata": {
        "id": "ujSno6HtHViv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "NVcApumAHXXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"sentence\": [\n",
        "        \"I love this product!\", \"This is the worst service ever.\", \"Absolutely fantastic experience.\",\n",
        "        \"I'm not happy with the results.\", \"The movie was okay, not great.\", \"What a wonderful surprise!\",\n",
        "        \"I would not recommend this.\", \"Such a delightful day.\", \"Terrible customer support.\",\n",
        "        \"This phone is amazing!\", \"Very disappointing performance.\", \"I'm so excited about this!\",\n",
        "        \"Could be better.\", \"Totally satisfied with my purchase.\", \"I hate how this works.\",\n",
        "        \"It exceeded my expectations!\", \"Nothing special about it.\", \"I'm impressed by the quality.\",\n",
        "        \"Worst purchase I've made.\", \"A pretty decent option.\"\n",
        "    ],\n",
        "    \"label\": [\n",
        "        \"positive\", \"negative\", \"positive\", \"negative\", \"neutral\", \"positive\", \"negative\",\n",
        "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"neutral\", \"positive\",\n",
        "        \"negative\", \"positive\", \"neutral\", \"positive\", \"negative\", \"neutral\"\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "B1MxDR8oHkBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"LLM Sentiment Evaluation\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "EDJxOiQxHoqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pd = pd.DataFrame(data)\n",
        "df_spark = spark.createDataFrame(df_pd)"
      ],
      "metadata": {
        "id": "nKS1rla6Hsn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_spark.toPandas()"
      ],
      "metadata": {
        "id": "5urnPsfJHyPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")  # Defaults to distilbert-base-uncased-finetuned-sst-2-english\n"
      ],
      "metadata": {
        "id": "A0RntT00H2Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_prediction(pred):\n",
        "    label = pred['label'].lower()\n",
        "    if label == 'positive':\n",
        "        return 'positive'\n",
        "    elif label == 'negative':\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "df['predicted'] = df['sentence'].apply(lambda x: map_prediction(classifier(x)[0]))\n"
      ],
      "metadata": {
        "id": "xcqkRcjPIk8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(df['label'], df['predicted'], digits=3))\n",
        "\n",
        "print(\"\\nAccuracy Score:\", accuracy_score(df['label'], df['predicted']))\n"
      ],
      "metadata": {
        "id": "wq1LNt9dJztd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_spark = spark.createDataFrame(df)\n",
        "df_result_spark.show(truncate=False)\n"
      ],
      "metadata": {
        "id": "ArxqZ_mOJ3v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "rL02NAZlJ92F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "from transformers import pipeline\n"
      ],
      "metadata": {
        "id": "27qOGEgtKAVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"SparkLLMSentiment\").getOrCreate()"
      ],
      "metadata": {
        "id": "i1b2vlqFKGzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"I love this product!\",),\n",
        "    (\"This is the worst service ever.\",),\n",
        "    (\"Absolutely fantastic experience.\",),\n",
        "    (\"I'm not happy with the results.\",),\n",
        "    (\"The movie was okay, not great.\",),\n",
        "    (\"What a wonderful surprise!\",),\n",
        "    (\"I would not recommend this.\",),\n",
        "    (\"Such a delightful day.\",),\n",
        "    (\"Terrible customer support.\",),\n",
        "    (\"This phone is amazing!\",),\n",
        "    (\"Very disappointing performance.\",),\n",
        "    (\"I'm so excited about this!\",),\n",
        "    (\"Could be better.\",),\n",
        "    (\"Totally satisfied with my purchase.\",),\n",
        "    (\"I hate how this works.\",),\n",
        "    (\"It exceeded my expectations!\",),\n",
        "    (\"Nothing special about it.\",),\n",
        "    (\"I'm impressed by the quality.\",),\n",
        "    (\"Worst purchase I've made.\",),\n",
        "    (\"A pretty decent option.\",)\n",
        "]\n",
        "\n",
        "columns = [\"sentence\"]\n",
        "df = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "vkCv84hlKL8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "    return pipeline(\"sentiment-analysis\")\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    global clf\n",
        "    if \"clf\" not in globals():\n",
        "        clf = load_model()\n",
        "    result = clf(text)[0]['label'].lower()\n",
        "    return result"
      ],
      "metadata": {
        "id": "a-mYu55sKSml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_udf = udf(predict_sentiment, StringType())\n",
        "df_with_predictions = df.withColumn(\"predicted_sentiment\", sentiment_udf(\"sentence\"))\n",
        "df_with_predictions.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of3t4TDlKXEl",
        "outputId": "636accd9-a05c-439a-af4f-417640096bce"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------+-------------------+\n",
            "|sentence                           |predicted_sentiment|\n",
            "+-----------------------------------+-------------------+\n",
            "|I love this product!               |positive           |\n",
            "|This is the worst service ever.    |negative           |\n",
            "|Absolutely fantastic experience.   |positive           |\n",
            "|I'm not happy with the results.    |negative           |\n",
            "|The movie was okay, not great.     |negative           |\n",
            "|What a wonderful surprise!         |positive           |\n",
            "|I would not recommend this.        |negative           |\n",
            "|Such a delightful day.             |positive           |\n",
            "|Terrible customer support.         |negative           |\n",
            "|This phone is amazing!             |positive           |\n",
            "|Very disappointing performance.    |negative           |\n",
            "|I'm so excited about this!         |positive           |\n",
            "|Could be better.                   |negative           |\n",
            "|Totally satisfied with my purchase.|positive           |\n",
            "|I hate how this works.             |negative           |\n",
            "|It exceeded my expectations!       |positive           |\n",
            "|Nothing special about it.          |negative           |\n",
            "|I'm impressed by the quality.      |positive           |\n",
            "|Worst purchase I've made.          |negative           |\n",
            "|A pretty decent option.            |positive           |\n",
            "+-----------------------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "m2eze3jsKdgs"
      },
      "execution_count": 68,
      "outputs": []
    }
  ]
}